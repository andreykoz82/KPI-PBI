{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# АНАЛИЗ ЗАПАСОВ ГОТОВОЙ ПРОДУКЦИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "non-default argument 'item' follows default argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m     sales \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(filename)\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m sales\n\u001b[0;32m     24\u001b[0m \u001b[39m@dataclass\u001b[39m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSalesTimeSeries\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     data: pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     item: \u001b[39mstr\u001b[39m\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\dataclasses.py:1021\u001b[0m, in \u001b[0;36mdataclass\u001b[1;34m(cls, init, repr, eq, order, unsafe_hash, frozen)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     \u001b[39mreturn\u001b[39;00m wrap\n\u001b[0;32m   1020\u001b[0m \u001b[39m# We're called as @dataclass without parens.\u001b[39;00m\n\u001b[1;32m-> 1021\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(\u001b[39mcls\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\dataclasses.py:1013\u001b[0m, in \u001b[0;36mdataclass.<locals>.wrap\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m-> 1013\u001b[0m     \u001b[39mreturn\u001b[39;00m _process_class(\u001b[39mcls\u001b[39;49m, init, \u001b[39mrepr\u001b[39;49m, eq, order, unsafe_hash, frozen)\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\dataclasses.py:927\u001b[0m, in \u001b[0;36m_process_class\u001b[1;34m(cls, init, repr, eq, order, unsafe_hash, frozen)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[39m# Include InitVars and regular fields (so, not ClassVars).\u001b[39;00m\n\u001b[0;32m    924\u001b[0m     flds \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fields\u001b[39m.\u001b[39mvalues()\n\u001b[0;32m    925\u001b[0m             \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39m_field_type \u001b[39min\u001b[39;00m (_FIELD, _FIELD_INITVAR)]\n\u001b[0;32m    926\u001b[0m     _set_new_attribute(\u001b[39mcls\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m__init__\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m--> 927\u001b[0m                        _init_fn(flds,\n\u001b[0;32m    928\u001b[0m                                 frozen,\n\u001b[0;32m    929\u001b[0m                                 has_post_init,\n\u001b[0;32m    930\u001b[0m                                 \u001b[39m# The name to use for the \"self\"\u001b[39;49;00m\n\u001b[0;32m    931\u001b[0m                                 \u001b[39m# param in __init__.  Use \"self\"\u001b[39;49;00m\n\u001b[0;32m    932\u001b[0m                                 \u001b[39m# if possible.\u001b[39;49;00m\n\u001b[0;32m    933\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39m__dataclass_self__\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39min\u001b[39;49;00m fields\n\u001b[0;32m    934\u001b[0m                                         \u001b[39melse\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    935\u001b[0m                                 \u001b[39mglobals\u001b[39;49m,\n\u001b[0;32m    936\u001b[0m                       ))\n\u001b[0;32m    938\u001b[0m \u001b[39m# Get the fields as a list, and include only real fields.  This is\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[39m# used in all of the following methods.\u001b[39;00m\n\u001b[0;32m    940\u001b[0m field_list \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fields\u001b[39m.\u001b[39mvalues() \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39m_field_type \u001b[39mis\u001b[39;00m _FIELD]\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\dataclasses.py:504\u001b[0m, in \u001b[0;36m_init_fn\u001b[1;34m(fields, frozen, has_post_init, self_name, globals)\u001b[0m\n\u001b[0;32m    502\u001b[0m             seen_default \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    503\u001b[0m         \u001b[39melif\u001b[39;00m seen_default:\n\u001b[1;32m--> 504\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnon-default argument \u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m.\u001b[39mname\u001b[39m!r}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    505\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mfollows default argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    507\u001b[0m \u001b[39mlocals\u001b[39m \u001b[39m=\u001b[39m {\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_type_\u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m: f\u001b[39m.\u001b[39mtype \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fields}\n\u001b[0;32m    508\u001b[0m \u001b[39mlocals\u001b[39m\u001b[39m.\u001b[39mupdate({\n\u001b[0;32m    509\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMISSING\u001b[39m\u001b[39m'\u001b[39m: MISSING,\n\u001b[0;32m    510\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m_HAS_DEFAULT_FACTORY\u001b[39m\u001b[39m'\u001b[39m: _HAS_DEFAULT_FACTORY,\n\u001b[0;32m    511\u001b[0m })\n",
      "\u001b[1;31mTypeError\u001b[0m: non-default argument 'item' follows default argument"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mplcyberpunk\n",
    "\n",
    "plt.style.use(\"cyberpunk\")\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def load_data(filename=\"sales_extend.xlsx\"):\n",
    "    sales = pd.read_excel(filename)\n",
    "    return sales\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SalesTimeSeries:\n",
    "    item: str\n",
    "    aggregation: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    data: pd.DataFrame = None\n",
    "    model: str = None\n",
    "    predictions: float = None\n",
    "    forecast: float = None\n",
    "    table: float = None\n",
    "\n",
    "    def transform(self):\n",
    "        if self.item == 'All':\n",
    "            self.data = self.data\n",
    "        else:\n",
    "            self.data = self.data[self.data['Номенклатура'] == self.item]\n",
    "        month_mapping = {'Январь': 1, 'Февраль': 2, 'Март': 3, 'Апрель': 4, 'Май': 5, 'Июнь': 6, 'Июль': 7,\n",
    "                         'Август': 8, 'Сентябрь': 9, 'Октябрь': 10, 'Ноябрь': 11, 'Декабрь': 12, }\n",
    "        month = self.data['По месяцам'].str.replace(' г.', \"\").str.split(' ', expand=True)[0].map(month_mapping)\n",
    "        year = self.data['По месяцам'].str.replace(' г.', \"\").str.split(' ', expand=True)[1]\n",
    "        df = month.to_frame().join(year)\n",
    "        df[0] = df[0].astype('str')\n",
    "        df[1] = df[1].astype('str')\n",
    "        df['date'] = df[0] + '-' + df[1]\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        self.data['По месяцам'] = df['date']\n",
    "        self.data = self.data.set_index('По месяцам')['Количество']\n",
    "        self.data = self.data[(self.data.index >= self.start_date) & (self.data.index <= self.end_date)]\n",
    "        self.data = self.data.groupby(pd.Grouper(freq=self.aggregation)).sum()\n",
    "\n",
    "    def train(self):\n",
    "        p = d = q = range(0, 2)\n",
    "        pdq = list(itertools.product(p, d, q))\n",
    "        seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "\n",
    "        res_aic = 9999\n",
    "        arima_param = 0\n",
    "        arima_param_seas = 0\n",
    "\n",
    "        for param in pdq:\n",
    "            for param_seasonal in seasonal_pdq:\n",
    "                try:\n",
    "                    mod = sm.tsa.statespace.SARIMAX(self.data,\n",
    "                                                    order=param,\n",
    "                                                    seasonal_order=param_seasonal,\n",
    "                                                    enforce_stationarity=False,\n",
    "                                                    enforce_invertibility=False)\n",
    "                    self.model = mod.fit()\n",
    "                    if self.model.aic < res_aic:\n",
    "                        res_aic = self.model.aic\n",
    "                        arima_param = param\n",
    "                        arima_param_seas = param_seasonal\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        mod = sm.tsa.statespace.SARIMAX(self.data,\n",
    "                                        order=arima_param,\n",
    "                                        seasonal_order=arima_param_seas,\n",
    "                                        enforce_stationarity=False,\n",
    "                                        enforce_invertibility=False)\n",
    "        self.model = mod.fit()\n",
    "\n",
    "    def predict(self):\n",
    "        self.predictions = self.model.get_prediction(start=self.data.index[0]).predicted_mean\n",
    "\n",
    "    def make_forecast(self):\n",
    "        self.forecast = self.model.get_forecast(steps=12).predicted_mean\n",
    "        \n",
    "    \n",
    "    def make_data_table(self):\n",
    "        self.table = pd.DataFrame(self.forecast).reset_index().rename(columns={'index': 'End_date'})\n",
    "        self.table['Begin_date'] = self.table['End_date'].astype(str).str[:7] + '-' + '01'\n",
    "        self.table['Begin_date'] = pd.to_datetime(self.table['Begin_date'])\n",
    "        self.table['bd_number'] = np.busday_count(begindates=self.table['Begin_date'].values.astype('datetime64[D]'), \n",
    "                                                     enddates=self.table['End_date'].values.astype('datetime64[D]'))\n",
    "        self.table['sales_per_day'] = self.table['predicted_mean'] / self.table['bd_number']\n",
    "        self.table['MAPE'] = np.mean(np.abs((self.data - self.predictions) / self.data)) * 100\n",
    "\n",
    "    def plot_time_series(self):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(self.data.index, self.data, marker='o', markersize=3, c='#08f5fd') # 7FFFD4\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Quantity')\n",
    "        plt.title(f\"{self.item} Time series plot\")\n",
    "        plt.grid(linestyle='--', c='grey')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        mplcyberpunk.add_glow_effects()\n",
    "        mplcyberpunk.add_gradient_fill(alpha_gradientglow=0.5, gradient_start='bottom')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_predictions(self):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        plt.plot(self.data.index, self.data, marker='o', markersize=3, c='#08f5fd')\n",
    "        plt.plot(self.predictions.index, self.predictions, marker='o', markersize=3, c='red')\n",
    "\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Quantity')\n",
    "        plt.title(f\"{self.item} Actual vs predicted plot\")\n",
    "        plt.grid(linestyle='--', c='grey')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        mplcyberpunk.add_glow_effects()\n",
    "        mplcyberpunk.add_gradient_fill(alpha_gradientglow=0.5, gradient_start='bottom')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_forecast(self):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(self.forecast.index, self.forecast, marker='o', markersize=5, c='#08f5fd', mfc='red')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Quantity')\n",
    "        plt.title(f\"{self.item} Forecast plot\", pad=20)\n",
    "        plt.grid(linestyle='--', c='grey')\n",
    "        plt.xticks(self.forecast.index, rotation=90)\n",
    "        for x, y in zip(self.forecast.index, self.forecast):\n",
    "            label = y\n",
    "            plt.annotate(f\"{round(label):,}\", (x, y),\n",
    "                         xycoords=\"data\",\n",
    "                         textcoords=\"offset points\",\n",
    "                         xytext=(0, 10), ha=\"center\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        mplcyberpunk.add_glow_effects()\n",
    "        mplcyberpunk.add_gradient_fill(alpha_gradientglow=0.5, gradient_start='bottom')\n",
    "        plt.show()\n",
    "\n",
    "    def show_metrics(self):\n",
    "        mape = np.mean(np.abs((self.data - self.predictions) / self.data)) * 100\n",
    "        me = np.mean(self.predictions - self.data)\n",
    "        mae = np.mean(np.abs(self.predictions - self.data))\n",
    "        mpe = np.mean((self.predictions - self.data) / self.data)\n",
    "        rmse = np.mean((self.predictions - self.data) ** 2) ** .5\n",
    "        corr = np.corrcoef(self.predictions, self.data)[0, 1]\n",
    "        mins = np.amin(np.hstack([self.predictions[:, None],\n",
    "                                  self.data[:, None]]), axis=1)\n",
    "        maxs = np.amax(np.hstack([self.predictions[:, None],\n",
    "                                  self.data[:, None]]), axis=1)\n",
    "        minmax = 1 - np.mean(mins / maxs)\n",
    "\n",
    "        metrics = {'mape': mape, 'me': me, 'mae': mae,\n",
    "                   'mpe': mpe, 'rmse': rmse, 'corr': corr, 'minmax': minmax}\n",
    "        print(metrics)\n",
    "\n",
    "    def save_forecast(self):\n",
    "        self.forecast.to_excel(\"forecast.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЗАГРУЗКА ДАННЫХ О ПРОДАЖАХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЗАГРУЗКА АКТУАЛЬНОГО СПИСКА ГОТОВОЙ ПРОДУКЦИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>production_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>2 stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Аир корневища 75г</td>\n",
       "      <td>Линия ББЛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Алтей корни 75г</td>\n",
       "      <td>Линия ББЛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Багульник болотный побеги 50г</td>\n",
       "      <td>Линия ББЛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Береза почки 50г</td>\n",
       "      <td>Линия ББЛ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            item production_line\n",
       "0                            All         2 stage\n",
       "1              Аир корневища 75г       Линия ББЛ\n",
       "2                Алтей корни 75г       Линия ББЛ\n",
       "3  Багульник болотный побеги 50г       Линия ББЛ\n",
       "4               Береза почки 50г       Линия ББЛ"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_items = pd.read_excel('actual_items.xlsx')\n",
    "actual_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАСЧЕТ ПРОГНОЗА ПРОДАЖ ПО КАЖДОМУ НАИМЕНОВАНИЮ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [36], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m actual_items\u001b[39m.\u001b[39mitem\u001b[39m.\u001b[39munique():\n\u001b[0;32m      5\u001b[0m     data \u001b[39m=\u001b[39m SalesTimeSeries(data\u001b[39m=\u001b[39msales, item\u001b[39m=\u001b[39mitem, aggregation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mM\u001b[39m\u001b[39m'\u001b[39m, start_date\u001b[39m=\u001b[39mstart_date, end_date\u001b[39m=\u001b[39mend_date)\n\u001b[1;32m----> 6\u001b[0m     data\u001b[39m.\u001b[39mtransform()\n\u001b[0;32m      7\u001b[0m     data\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      8\u001b[0m     data\u001b[39m.\u001b[39mpredict()\n",
      "Cell \u001b[1;32mIn [27], line 43\u001b[0m, in \u001b[0;36mSalesTimeSeries.transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mНоменклатура\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem]\n\u001b[0;32m     41\u001b[0m month_mapping \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mЯнварь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mФевраль\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mМарт\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m3\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mАпрель\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m4\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mМай\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m5\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mИюнь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m6\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mИюль\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m7\u001b[39m,\n\u001b[0;32m     42\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mАвгуст\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m8\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mСентябрь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m9\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mОктябрь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mНоябрь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m11\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mДекабрь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m12\u001b[39m, }\n\u001b[1;32m---> 43\u001b[0m month \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[\u001b[39m'\u001b[39;49m\u001b[39mПо месяцам\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m г.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, expand\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmap(month_mapping)\n\u001b[0;32m     44\u001b[0m year \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mПо месяцам\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m г.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, expand\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m     45\u001b[0m df \u001b[39m=\u001b[39m month\u001b[39m.\u001b[39mto_frame()\u001b[39m.\u001b[39mjoin(year)\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[0;32m    183\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:177\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m    175\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstring_\u001b[39;00m \u001b[39mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(data)\n\u001b[0;32m    178\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_categorical \u001b[39m=\u001b[39m is_categorical_dtype(data\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_string \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(data\u001b[39m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:231\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    228\u001b[0m inferred_dtype \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39minfer_dtype(values, skipna\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m inferred_dtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 231\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .str accessor with string values!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "time_series = {}\n",
    "start_date = '2012-01-01'\n",
    "end_date = '2022-10-01'\n",
    "for item in actual_items.item.unique():\n",
    "    data = SalesTimeSeries(data=sales, item=item, aggregation='M', start_date=start_date, end_date=end_date)\n",
    "    data.transform()\n",
    "    data.train()\n",
    "    data.predict()\n",
    "    data.make_forecast()\n",
    "    data.make_data_table()\n",
    "    time_series[item] = data.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ЭКСПОРТ ПРОГНОЗА В ФАЙЛ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('time_series_10_22.pkl', 'wb') as f:\n",
    "    pickle.dump(time_series, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ИМПОРТ ПРОГНОЗА ИЗ ФАЙЛА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('time_series_10_22.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ЗАГРУЗКА ОСТАТКОВ ГОТОВОЙ ПРОДУКЦИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Наименование</th>\n",
       "      <th>Количество</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ВердиоГаст® Растительный комплекс для улучшени...</td>\n",
       "      <td>81632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Чага (березовый гриб) 50г</td>\n",
       "      <td>17570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Спорыш трава 50г</td>\n",
       "      <td>11335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Сб. Фитогепатол №2 (Желчегонный сбор №2) 35г</td>\n",
       "      <td>3181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Солодка корни 50г</td>\n",
       "      <td>31238.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Наименование  Количество\n",
       "0  ВердиоГаст® Растительный комплекс для улучшени...     81632.0\n",
       "1                          Чага (березовый гриб) 50г     17570.0\n",
       "2                                   Спорыш трава 50г     11335.0\n",
       "3       Сб. Фитогепатол №2 (Желчегонный сбор №2) 35г      3181.0\n",
       "4                                  Солодка корни 50г     31238.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.read_excel('finish_goods_stocks.xlsx')\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_stock_level(item, stocks, forecast):\n",
    "    date_index = pd.date_range(start=forecast[item]['Begin_date'].iloc[0], \n",
    "                end=forecast[item]['End_date'].iloc[-1], freq='B')\n",
    "    temp = pd.DataFrame(index=date_index)\n",
    "    current_date = pd.to_datetime('today').normalize()\n",
    "    temp = temp[temp.index>=current_date]\n",
    "    temp['Остаток'] = stocks[stocks['Наименование'] == item]['Количество'].item()\n",
    "    i = 0\n",
    "    dead_line = 0\n",
    "    stock_level = 0\n",
    "    for date, stock in temp.iterrows():\n",
    "        year = date.year\n",
    "        month = date.month\n",
    "        stat = forecast[item][(forecast[item]['End_date'].dt.year == year) & (forecast[item]['End_date'].dt.month == month)]\n",
    "        sales_per_day = stat['sales_per_day'].item()\n",
    "        if i == 0:\n",
    "            temp['Остаток'].iloc[i] == temp['Остаток'][i]\n",
    "        else:\n",
    "            temp['Остаток'].iloc[i] = temp['Остаток'].iloc[i - 1] - sales_per_day\n",
    "            if temp['Остаток'].iloc[i] < 0:\n",
    "                temp['Остаток'].iloc[i:] = 0\n",
    "                stock_level = temp.astype(bool).sum(axis=0).item()\n",
    "                temp['DeadLine'] = 0\n",
    "                if i <= 0:\n",
    "                    temp['DeadLine'].iloc[0] = 'DeadLine'\n",
    "                else:\n",
    "                    temp['DeadLine'].iloc[i - 6] = 'DeadLine'\n",
    "                dead_line = temp[temp['DeadLine'] == 'DeadLine'].index\n",
    "                dead_line = pd.Series(dead_line.format())[0]\n",
    "                break\n",
    "            if i == temp.shape[0] - 1:\n",
    "                stock_level = temp.astype(bool).sum(axis=0).item()\n",
    "                break\n",
    "        i += 1\n",
    "    item_stock = stocks[stocks['Наименование'] == item]['Количество'].item()\n",
    "    mape = forecast[item]['MAPE'][0]\n",
    "    \n",
    "    return item_stock, stock_level, mape, temp, dead_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'All'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m final_data \u001b[39m=\u001b[39m {}\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m actual_items\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m----> 3\u001b[0m     item_stock, stock_level, mape, temp_data, dead_line \u001b[39m=\u001b[39m calculate_stock_level(row[\u001b[39m0\u001b[39m], stocks, loaded_dict)\n\u001b[0;32m      4\u001b[0m     final_data[row[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m [row[\u001b[39m1\u001b[39m], stock_level, item_stock, \u001b[39mround\u001b[39m(mape, \u001b[39m0\u001b[39m), temp_data, dead_line]\n",
      "Cell \u001b[1;32mIn [32], line 2\u001b[0m, in \u001b[0;36mcalculate_stock_level\u001b[1;34m(item, stocks, forecast)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_stock_level\u001b[39m(item, stocks, forecast):\n\u001b[1;32m----> 2\u001b[0m     date_index \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mdate_range(start\u001b[39m=\u001b[39mforecast[item][\u001b[39m'\u001b[39m\u001b[39mBegin_date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m], \n\u001b[0;32m      3\u001b[0m                 end\u001b[39m=\u001b[39mforecast[item][\u001b[39m'\u001b[39m\u001b[39mEnd_date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], freq\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     temp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mdate_index)\n\u001b[0;32m      5\u001b[0m     current_date \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(\u001b[39m'\u001b[39m\u001b[39mtoday\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mnormalize()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'All'"
     ]
    }
   ],
   "source": [
    "final_data = {}\n",
    "for idx, row in actual_items.iterrows():\n",
    "    item_stock, stock_level, mape, temp_data, dead_line = calculate_stock_level(row[0], stocks, loaded_dict)\n",
    "    final_data[row[0]] = [row[1], stock_level, item_stock, round(mape, 0), temp_data, dead_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = (pd.DataFrame.from_dict(final_data, orient='index')\n",
    ".rename(columns={0: 'Линия производства', \n",
    "                 1: 'Запасы (дней)', \n",
    "                 2: 'Остатки (шт.)', \n",
    "                 3: 'MAPE',\n",
    "                 5: 'DeadLine'})\n",
    ".sort_values(by=['Линия производства', 'Запасы (дней)'])\n",
    ".drop(4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ЭКСПОРТ ДАННЫХ В EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_table.to_excel('stock_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ВИЗУАЛИЗАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a621182fbca34cb2936e6476b18900f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Item:', index=1, options=('All', 'Аир корневища 75г', 'Алтей корни 75г', 'Багульник боло…"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "\n",
    "selected_item = widgets.Dropdown(\n",
    "    options=actual_items.item.unique(),\n",
    "    value='Аир корневища 75г',\n",
    "    description='Item:',\n",
    ")\n",
    "selected_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m temp \u001b[39m=\u001b[39m SalesTimeSeries(data\u001b[39m=\u001b[39msales, item\u001b[39m=\u001b[39mselected_item\u001b[39m.\u001b[39mvalue, aggregation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mM\u001b[39m\u001b[39m'\u001b[39m, start_date\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2012-01-01\u001b[39m\u001b[39m'\u001b[39m, end_date\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2022-10-01\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m temp\u001b[39m.\u001b[39mtransform()\n\u001b[0;32m      3\u001b[0m temp\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      4\u001b[0m temp\u001b[39m.\u001b[39mpredict()\n",
      "Cell \u001b[1;32mIn [27], line 43\u001b[0m, in \u001b[0;36mSalesTimeSeries.transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mНоменклатура\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem]\n\u001b[0;32m     41\u001b[0m month_mapping \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mЯнварь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mФевраль\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mМарт\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m3\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mАпрель\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m4\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mМай\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m5\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mИюнь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m6\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mИюль\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m7\u001b[39m,\n\u001b[0;32m     42\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mАвгуст\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m8\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mСентябрь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m9\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mОктябрь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mНоябрь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m11\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mДекабрь\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m12\u001b[39m, }\n\u001b[1;32m---> 43\u001b[0m month \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[\u001b[39m'\u001b[39;49m\u001b[39mПо месяцам\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m г.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, expand\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmap(month_mapping)\n\u001b[0;32m     44\u001b[0m year \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mПо месяцам\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m г.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, expand\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m     45\u001b[0m df \u001b[39m=\u001b[39m month\u001b[39m.\u001b[39mto_frame()\u001b[39m.\u001b[39mjoin(year)\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[0;32m    183\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:177\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m    175\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstring_\u001b[39;00m \u001b[39mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(data)\n\u001b[0;32m    178\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_categorical \u001b[39m=\u001b[39m is_categorical_dtype(data\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_string \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(data\u001b[39m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32md:\\Miniconda3\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:231\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    228\u001b[0m inferred_dtype \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39minfer_dtype(values, skipna\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m inferred_dtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 231\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .str accessor with string values!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "temp = SalesTimeSeries(data=sales, item=selected_item.value, aggregation='M', start_date='2012-01-01', end_date='2022-10-01')\n",
    "temp.transform()\n",
    "temp.train()\n",
    "temp.predict()\n",
    "temp.make_forecast()\n",
    "temp.make_data_table()\n",
    "temp.plot_time_series()\n",
    "temp.plot_predictions()\n",
    "temp.plot_forecast()\n",
    "temp.show_metrics()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "nl = '\\n'\n",
    "idx = (final_data[selected_item.value][4]['Остаток'] > 0).sum() + 1\n",
    "dead_line = final_data[selected_item.value][4][final_data[selected_item.value][4]['DeadLine'] == 'DeadLine'].index\n",
    "ax.bar(final_data[selected_item.value][4].iloc[:idx].index, final_data[selected_item.value][4].iloc[:idx]['Остаток'])\n",
    "ax.axvline(x=dead_line, ymin=0, ymax=final_data[selected_item.value][4].head(20)['Остаток'].max(), color='red', zorder=2)\n",
    "ax.set_title(f'Диаграмма изменения запасов ГП для {selected_item.value}, {nl}DeadLine at {dead_line.strftime(\"%Y-%m-%d\")[0]}')\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "myFmt = DateFormatter(\"%Y-%m-%d\")\n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    "ax.tick_params(axis='x', rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "По месяцам\n",
       "2012-01-31    2669223\n",
       "2012-02-29    6485887\n",
       "2012-03-31    5840992\n",
       "2012-04-30    4119313\n",
       "2012-05-31    3388387\n",
       "               ...   \n",
       "2022-06-30    2289493\n",
       "2022-07-31    1615221\n",
       "2022-08-31    2313593\n",
       "2022-09-30    3956055\n",
       "2022-10-31    3167826\n",
       "Freq: M, Name: Количество, Length: 130, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4442a059423b1d8cb2d566f1d7a9e596fd1852f4b9b9e9d6f69b72f942b31330"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
